{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb6d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 829618 della-vis1.princeton.edu\n",
      "3 829620 della-vis1.princeton.edu\n",
      "4 829621 della-vis1.princeton.edu\n",
      "5 829622 della-vis1.princeton.edu\n",
      "6 829624 della-vis1.princeton.edu\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "using Distributed,ClusterManagers\n",
    "\n",
    "cpus_per_task = 5;\n",
    "addprocs(cpus_per_task, exeflags=[\"--threads=5\", \"--project=$(Base.active_project())\"])\n",
    "\n",
    "for i in workers()\n",
    "    id, pid, host = fetch(@spawnat i (myid(), getpid(), gethostname()))\n",
    "    println(id, \" \" , pid, \" \", host)\n",
    "end\n",
    "\n",
    "Threads.@threads for i in workers()\n",
    "    tid = Threads.threadid()\n",
    "    println(tid)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc089fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task running on thread 2 at time 2024-05-13T18:26:18.082\n",
      "Task running on thread 5 at time 2024-05-13T18:26:18.173\n",
      "Task running on thread 4 at time 2024-05-13T18:26:18.275\n",
      "Task running on thread 3 at time 2024-05-13T18:26:18.376\n",
      "Task running on thread 4 at time 2024-05-13T18:26:18.478\n"
     ]
    }
   ],
   "source": [
    "using Distributed,ClusterManagers\n",
    "using Base.Threads\n",
    "using Dates\n",
    "\n",
    "@everywhere function init_proc()\n",
    "    \n",
    "\n",
    "# do work on a processor in a multithreaded fashion\n",
    "@everywhere function do_proc_work_multithreaded()\n",
    "    # Shared channel for task distribution\n",
    "    global task_queue = RemoteChannel(()->Channel{Function}(32));\n",
    "\n",
    "    # Worker function that continuously takes tasks from the queue and executes them\n",
    "    function worker()\n",
    "        while true\n",
    "            func = take!(task_queue)  # Take a function from the queue\n",
    "            func()  # Execute the function\n",
    "        end\n",
    "    end\n",
    "\n",
    "    worker_tasks = []\n",
    "    \n",
    "    # Start a set of worker threads\n",
    "    for i in 1:Threads.nthreads()\n",
    "        push!(worker_tasks, Threads.@spawn worker())\n",
    "    end\n",
    "\n",
    "    # Example function to put tasks into the queue\n",
    "    function enqueue_tasks(n)\n",
    "        for i in 1:n\n",
    "            put!(task_queue, () -> begin\n",
    "                thread_id = Threads.threadid()\n",
    "                println(\"Task running on thread $thread_id at time $(now())\")\n",
    "                sleep(rand())  # Random delay to simulate work\n",
    "            end)\n",
    "            sleep(0.1)  # Throttle task creation\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Start task enqueueing in a separate thread\n",
    "    et = Threads.@spawn enqueue_tasks(5)\n",
    "    wait(et)\n",
    "    \n",
    "    for task in worker_tasks\n",
    "        wait(task)\n",
    "    end\n",
    "end\n",
    "\n",
    "do_proc_work_multithreaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed,ClusterManagers\n",
    "addprocs(4);\n",
    "\n",
    "global jobs = RemoteChannel(()->Channel{Int}(32));\n",
    "global results = RemoteChannel(()->Channel{Tuple}(32));\n",
    "\n",
    "n=12;\n",
    "exec_time=1\n",
    "\n",
    "@everywhere function do_work(jobs, results) # define work function everywhere\n",
    "    while true\n",
    "        job_id = try\n",
    "            take!(jobs)\n",
    "        catch\n",
    "            return # exit early if channel closed\n",
    "        end\n",
    "        exec_time = rand()\n",
    "        sleep(exec_time) # simulates elapsed time doing actual work\n",
    "        put!(results, (job_id, exec_time, myid()))\n",
    "    end\n",
    "end\n",
    "\n",
    "function make_jobs(n)\n",
    "   for i in 1:n\n",
    "       put!(jobs, i)\n",
    "   end\n",
    "end;\n",
    "\n",
    "for p in workers()\n",
    "    remote_do(do_work, p, jobs, results)\n",
    "end\n",
    "\n",
    "function mono_mga()\n",
    "    make_jobs(n)\n",
    "\n",
    "    # Take results\n",
    "    try\n",
    "        for _ in 1:5\n",
    "            job_id, exec_time, worker_id = take!(results)\n",
    "            println(\"Job $job_id finished in $exec_time seconds on worker $worker_id\")\n",
    "        end\n",
    "    catch e\n",
    "        println(\"Failed to take from results: $e\")\n",
    "    end\n",
    "end\n",
    "\n",
    "@elapsed mono_mga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15315e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_dist_helpers()\n",
    "    ##### Initialize a distributed arrays of JuMP models\n",
    "    ## Start pre-solve timer\n",
    "    subproblem_generation_time = time()\n",
    "    \n",
    "    num_procs = ENV[\"SLURM_CPUS_PER_TASK\"]\n",
    "    helpers_all = distribute([Dict() for i in 1:num_procs]);\n",
    "    workers_all = workers()\n",
    "\n",
    "    @sync for i in 1:num_procs\n",
    "        p = workers_all[i]\n",
    "        @async @spawnat p begin\n",
    "            W_local = localindices(helpers_all)[1];\n",
    "            inputs_local = [inputs_decomp[k] for k in W_local];\n",
    "            SUBPROB_OPTIMIZER =  configure_benders_subprob_solver(setup[\"Solver\"], setup[\"settings_path\"]);\n",
    "            init_local_helper!(setup,inputs_local,localpart(helpers_all),master_vars,master_cons,SUBPROB_OPTIMIZER);\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # master_vars_sub = Dict();\n",
    "    # for i in eachindex(helpers_all)\n",
    "    #   w = helpers_all[i][\"SubPeriod\"];\n",
    "    #   master_vars_sub[w] = helpers_all[i][\"master_vars_sub\"];\n",
    "    # end\n",
    "\n",
    "    p_id = workers_all[1:num_sub];\n",
    "    np_id = length(p_id);\n",
    "\n",
    "    master_vars_sub = [Dict() for k in 1:np_id];\n",
    "\n",
    "    @sync for k in 1:np_id\n",
    "              @async master_vars_sub[k]= @fetchfrom p_id[k] get_local_master_vars(localpart(helpers_all))\n",
    "    end\n",
    "\n",
    "    master_vars_sub = merge(master_vars_sub...);\n",
    "\n",
    "    ## Record pre-solver time\n",
    "    subproblem_generation_time = time() - subproblem_generation_time\n",
    "    println(\"Distributed operational subproblems generation took $subproblem_generation_time seconds\")\n",
    "\n",
    "    return helpers_all,master_vars_sub\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58254c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
